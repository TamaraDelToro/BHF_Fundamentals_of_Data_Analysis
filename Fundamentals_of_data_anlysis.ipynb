{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN6BHD9QzVNSmFr9k5Jmufs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TamaraDelToro/BHF_Fundamentals_of_Data_Analysis/blob/main/Fundamentals_of_data_anlysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fundamentals of Data analysis\n",
        "\n",
        "This is a quick hands-on exercise to explore data types, distributions and exploratory data analysis."
      ],
      "metadata": {
        "id": "UwNMlZIztZr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding data types and properties of data\n",
        "**Data distributions and why they matter**\n",
        "\n",
        "The distribution of your observations alone holds a lot of information about the data you are looking at.\n",
        "\n",
        "I won't explain what differet distributions there are as you probably already know the main ones, and these will become clearer as you work with your data.\n",
        "\n",
        "Instead lets have a little play to say how exploring data distributions might be a useful first explorations for your data analysis.\n",
        "\n",
        "Firstly, lets define the experiment:\n",
        "\n",
        "We are collecting heart rate data from participants taking a new drug for heart failure.\n",
        "\n",
        "We want to look at the data, so we get a better understanding about heart rates in our sample.\n",
        "\n",
        "To work this tutorial, you don't need to re-write any code, please just click the run icon (to the top left of the code windows) to execute the code, and have a look at the outputs you are getting.\n",
        "\n",
        "Can you spot any issues with the distribution of the heart rate data?\n",
        "\n",
        "What were you expecting instead?"
      ],
      "metadata": {
        "id": "TMC0awhmYPIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this block, I will just generate the data we will work with\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate random normal distribution data for resting heart rates (in bpm)\n",
        "np.random.seed(42)  # For reproducibility\n",
        "heart_rates_normal = np.random.normal(loc=70, scale=10, size=500)  # Normal distribution\n",
        "\n",
        "# add extra values\n",
        "heart_rates_data = np.append(heart_rates_normal, [200, 210, 215])  # Adding extra readings"
      ],
      "metadata": {
        "id": "dW0-GWUrfwf4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heart rate monitor data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(heart_rates_data, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Distribution of Resting Heart Rates\")\n",
        "plt.xlabel(\"Resting Heart Rate (bpm)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PCIgU75jgJNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see the distribution in our graph isn't normal.\n",
        "After a few more exploration steps you realise all the outliers come from the same heart rate monitor, which is faulty.\n",
        "\n",
        "Understanding the distribution you can expect, and subsequently looking at the distribution you have can help you identify issues such as faulty equipment, extreme outliers, data loading trouble, and more."
      ],
      "metadata": {
        "id": "SwxlfiaZqSHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data analysis\n",
        "\n",
        "Exploratry data analysis is very important to understand your data, and the relationships and patterns within it.\n",
        "\n",
        "Many papers are published on exploratpry findings alone.\n",
        "\n",
        "Lets see how carrying out some initial exploratory analysis of our data can help us plan further work.\n",
        "\n",
        "We are using an open source dataset from UC Irvine on the prevalence of heart disease.\n",
        "\n",
        "Here, we will look at the properties of the dataset, the descriptive statistics, we will check for any missing data, and explore any correlations between our variables."
      ],
      "metadata": {
        "id": "Pg3pxzAIkhI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset directly from UCI Machine Learning Repository\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
        "columns = [\"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"target\"]\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Show the first few rows of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hmhMZQ8ktvQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the dataset\n",
        "print(f\"Dataset shape: {df.shape}\") # lets you see how many rows and colums you have. Do you have as expected?\n",
        "\n",
        "# Check for missing values or unusual data types\n",
        "df.info()"
      ],
      "metadata": {
        "id": "uvkYgAPBuCBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for numerical columns\n",
        "df.describe() # Produce summary statistics (mean, median, standard deviation, ect) for numerical columns"
      ],
      "metadata": {
        "id": "a_XVfuEquk7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do you think this might be an important step in data analysis?"
      ],
      "metadata": {
        "id": "6CqDvZU6u9id"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As part of your data pre-procesing, you will handle any missing data.\n",
        "Lets see how you can do that in python:"
      ],
      "metadata": {
        "id": "_G9XejkZvGmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '?' with NaN to identify missing data\n",
        "df.replace(\"?\", pd.NA, inplace=True)\n",
        "\n",
        "# Convert appropriate columns to numeric where necessary\n",
        "df[\"ca\"] = pd.to_numeric(df[\"ca\"], errors='coerce')\n",
        "df[\"thal\"] = pd.to_numeric(df[\"thal\"], errors='coerce')\n",
        "\n",
        "# Check how many missing values exist\n",
        "df.isnull().sum()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9TjxrxIHvC6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many missing values do you have in this dataset?\n",
        "\n",
        "While we now know we dont always need to drop all missing values, but we can impute instead, we will just drop them in this case as theres not too many!"
      ],
      "metadata": {
        "id": "e4vCFzX9voIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally drop rows with missing data\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "q08HSqR8vbYG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vizualising your data is a great way to explore its distributions and initial patterns."
      ],
      "metadata": {
        "id": "KSJXW0Oqv6Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Countplot for the target variable\n",
        "sns.countplot(x=\"target\", data=df)\n",
        "plt.title(\"Heart Disease Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dKg245xzv5XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of age\n",
        "sns.histplot(df['age'], kde=True, bins=20, color='blue')\n",
        "plt.title('Age Distribution')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "StTSehNewDmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As part of your exploratory analysis you might also explore how some of your variables might correlate to each other.\n",
        "\n",
        "A correlation heatmap is a great way to look at that!"
      ],
      "metadata": {
        "id": "mrS5M-orwMqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tPa91vctwTWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or if you are a more advanced analyst you might use a pairplot!"
      ],
      "metadata": {
        "id": "rc-f_cL8wpcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot of key features\n",
        "sns.pairplot(df[[\"age\", \"chol\", \"thalach\", \"trestbps\", \"target\"]], hue=\"target\", palette='Set1')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Rg-jjS3wcFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly you might want to have a look at specific features instead.\n",
        "\n",
        "Let’s dive into specific features that might be relevant for cardiovascular research, such as cholesterol (chol), maximum heart rate (thalach), and resting blood pressure (trestbps)."
      ],
      "metadata": {
        "id": "IT53TKsSwz_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot of cholesterol levels by heart disease status\n",
        "sns.boxplot(x=\"target\", y=\"chol\", data=df)\n",
        "plt.title('Cholesterol Levels vs. Heart Disease')\n",
        "plt.xlabel('Heart Disease')\n",
        "plt.ylabel('Cholesterol (mg/dl)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kFkwdOXww5dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of max heart rate (thalach) and age, colored by heart disease\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x=\"age\", y=\"thalach\", hue=\"target\", data=df, palette='Set1')\n",
        "plt.title(\"Max Heart Rate (Thalach) vs. Age\")\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Max Heart Rate (Thalach)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "27T1u7yyxCwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Through this simple exploratory data analysis we have covered quite a bit of ground towards doing some analysis, including exploring some relationships between features and the presence of heart disease by visualising the data.\n",
        "\n",
        "This exploratory analysis helps identify potential trends and relationships that can guide further modeling or hypothesis testing in cardiovascular research.\n",
        "\n",
        "You can also use this code for any data you might produce!"
      ],
      "metadata": {
        "id": "Z_B0VXnlw5DL"
      }
    }
  ]
}